{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbh25-10120-cloud/DynamicBind/blob/main/DynamicBind_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb1f93c1",
      "metadata": {
        "id": "fb1f93c1"
      },
      "source": [
        "## Step 1: Check GPU and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7021fbc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7021fbc0",
        "outputId": "352194e6-7080-4595-c794-d344b59396c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "✓ Repository already exists (git repo)\n",
            "Working directory: /content/DynamicBind\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected. Go to Runtime > Change runtime type and select GPU.\")\n",
        "\n",
        "# Set working directory\n",
        "os.chdir('/content')\n",
        "\n",
        "# If a non-git `DynamicBind` folder exists, remove it so a fresh clone can proceed\n",
        "if os.path.exists('DynamicBind') and not os.path.exists(os.path.join('DynamicBind', '.git')):\n",
        "    print(\"Removing non-git 'DynamicBind' directory to allow fresh clone...\")\n",
        "    shutil.rmtree('DynamicBind')\n",
        "\n",
        "# Clone from original repo (or you can upload a ZIP)\n",
        "if not os.path.exists('DynamicBind'):\n",
        "    print(\"Cloning DynamicBind repository...\")\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/luwei0917/DynamicBind.git', 'DynamicBind'], check=True)\n",
        "    print(\"✓ Repository cloned\")\n",
        "else:\n",
        "    print(\"✓ Repository already exists (git repo)\")\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "260b2184",
      "metadata": {
        "id": "260b2184"
      },
      "source": [
        "## Step 2: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfdd0bee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfdd0bee",
        "outputId": "60da98cf-4b0c-4512-ef6d-e9f7202da596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyTorch...\n",
            "Installing PyTorch Geometric...\n",
            "Installing RDKit and other dependencies...\n",
            "Installing ESM and spyrmsd...\n",
            "\n",
            "✓ All dependencies installed successfully\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing PyTorch...\")\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "print(\"Installing PyTorch Geometric...\")\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "print(\"Installing RDKit and other dependencies...\")\n",
        "!pip install -q rdkit biopython pandas numpy scipy scikit-learn matplotlib tqdm pyyaml requests\n",
        "\n",
        "print(\"Installing ESM and spyrmsd...\")\n",
        "!pip install -q fair-esm spyrmsd e3nn\n",
        "\n",
        "print(\"\\n✓ All dependencies installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5304492",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5304492",
        "outputId": "d459cd3e-8f52-4961-f1fb-2316ea57bc45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Running in Colab - using notebook kernel (conda not available)\n",
            "  All required packages were installed in Step 2 via pip\n",
            "  Skipping conda environment setup\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Detect if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False\n",
        "\n",
        "if in_colab:\n",
        "    print(\"✓ Running in Colab - using notebook kernel (conda not available)\")\n",
        "    print(\"  All required packages were installed in Step 2 via pip\")\n",
        "    print(\"  Skipping conda environment setup\")\n",
        "else:\n",
        "    # Local machine with conda installed\n",
        "    os.chdir('/content/DynamicBind')\n",
        "\n",
        "    print(\"Setting up Conda environment for DynamicBind...\")\n",
        "    print(\"This step ensures all PyTorch Geometric dependencies are installed.\\n\")\n",
        "\n",
        "    # Create conda environment from environment-minimal.yml\n",
        "    if not os.path.exists(os.path.expanduser('~/miniconda3/envs/dynamicbind-minimal')):\n",
        "        print(\"Creating dynamicbind-minimal environment...\")\n",
        "        result = subprocess.run(['conda', 'env', 'create', '-f', 'environment-minimal.yml', '-y'],\n",
        "                              capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"✓ Environment created successfully\")\n",
        "        else:\n",
        "            print(\"⚠ Environment creation had issues:\")\n",
        "            print(result.stderr[-500:])  # Last 500 chars\n",
        "    else:\n",
        "        print(\"✓ Environment already exists\")\n",
        "\n",
        "    # Verify torch_cluster is installed\n",
        "    print(\"\\nVerifying torch_cluster installation...\")\n",
        "    result = subprocess.run(['conda', 'run', '-n', 'dynamicbind-minimal', 'python', '-c',\n",
        "                            'import torch_cluster; print(\"✓ torch_cluster found\")'],\n",
        "                           capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(result.stdout.strip())\n",
        "    else:\n",
        "        print(\"⚠ torch_cluster not found, installing...\")\n",
        "        subprocess.run(['conda', 'install', '-n', 'dynamicbind-minimal',\n",
        "                       '-c', 'pytorch', 'pytorch-cluster', '-y'],\n",
        "                      capture_output=True)\n",
        "        print(\"✓ torch_cluster installed\")\n",
        "\n",
        "    print(\"\\n✓ Conda environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e64225",
      "metadata": {
        "id": "32e64225"
      },
      "source": [
        "## Step 3: Clone/Setup DynamicBind Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdb5adc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abdb5adc",
        "outputId": "ee669a00-5e70-4c03-9900-c2c454165680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Repository already exists\n",
            "Working directory: /content/DynamicBind\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "os.chdir('/content')\n",
        "\n",
        "# Clone from original repo (or you can upload a ZIP)\n",
        "if not os.path.exists('DynamicBind'):\n",
        "    !git clone https://github.com/luwei0917/DynamicBind.git\n",
        "    print(\"✓ Repository cloned\")\n",
        "else:\n",
        "    print(\"✓ Repository already exists\")\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab327d0",
      "metadata": {
        "id": "7ab327d0"
      },
      "source": [
        "## Step 4: Download Model Checkpoints from Zenodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efc320d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efc320d3",
        "outputId": "4eedc957-0fb0-4671-e7c8-bfb7e322b053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Checkpoints already available\n",
            "Workdir contents: ['workdir', 'big_score_model_sanyueqi_with_time']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "os.makedirs('workdir', exist_ok=True)\n",
        "\n",
        "# Download checkpoint from Zenodo (v2)\n",
        "checkpoint_url = 'https://zenodo.org/records/10183369/files/workdir.zip'\n",
        "checkpoint_file = 'workdir.zip'\n",
        "\n",
        "if not os.path.exists(os.path.join('workdir', 'big_score_model_sanyueqi_with_time')):\n",
        "    print(f\"Downloading model checkpoint from Zenodo (may take 5-10 minutes)...\")\n",
        "    !wget -O {checkpoint_file} {checkpoint_url}\n",
        "    print(\"Extracting...\")\n",
        "    !unzip -o {checkpoint_file} -d workdir\n",
        "    # Fix nested directory structure if needed\n",
        "    if os.path.exists('workdir/workdir'):\n",
        "        !mv workdir/workdir/* workdir/\n",
        "        !rmdir workdir/workdir\n",
        "    print(\"✓ Checkpoints ready\")\n",
        "    !rm {checkpoint_file}\n",
        "else:\n",
        "    print(\"✓ Checkpoints already available\")\n",
        "\n",
        "print(f\"Workdir contents: {os.listdir('workdir')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fbe7cf8",
      "metadata": {
        "id": "4fbe7cf8"
      },
      "source": [
        "## Step 5: Upload Input Files (PDB & SDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6a4ef4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ea6a4ef4",
        "outputId": "a7da73a7-2dd0-414c-e113-dddd4c5a7b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your protein PDB file and ligand SDF file.\n",
            "Click 'Choose Files' and select both files.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43d0ed2e-c0d3-4847-9114-3e76b3535542\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43d0ed2e-c0d3-4847-9114-3e76b3535542\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Conformer3D_COMPOUND_CID_977.sdf to Conformer3D_COMPOUND_CID_977.sdf\n",
            "Saving unnamed.pdb to unnamed.pdb\n",
            "✓ PDB: input/unnamed.pdb\n",
            "✓ SDF: input/Conformer3D_COMPOUND_CID_977.sdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "os.makedirs('/content/DynamicBind/input', exist_ok=True)\n",
        "os.chdir('/content/DynamicBind')\n",
        "\n",
        "print(\"Upload your protein PDB file and ligand SDF file.\")\n",
        "print(\"Click 'Choose Files' and select both files.\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "pdb_file = None\n",
        "sdf_file = None\n",
        "\n",
        "for fname in uploaded.keys():\n",
        "    if fname.endswith('.pdb'):\n",
        "        pdb_file = f'input/{fname}'\n",
        "        os.rename(fname, pdb_file)\n",
        "    elif fname.endswith('.sdf'):\n",
        "        sdf_file = f'input/{fname}'\n",
        "        os.rename(fname, sdf_file)\n",
        "\n",
        "if pdb_file and sdf_file:\n",
        "    print(f\"✓ PDB: {pdb_file}\")\n",
        "    print(f\"✓ SDF: {sdf_file}\")\n",
        "else:\n",
        "    print(\"ERROR: Please upload both PDB and SDF files.\")\n",
        "    if pdb_file:\n",
        "        print(f\"  PDB found: {pdb_file}\")\n",
        "    if sdf_file:\n",
        "        print(f\"  SDF found: {sdf_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f70b64b",
      "metadata": {
        "id": "7f70b64b"
      },
      "source": [
        "## Step 6: Prepare Input CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b26f27a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b26f27a",
        "outputId": "8bda05af-89ee-498f-8f1e-a960f900691f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Input CSV created\n",
            "                                              ligand  \\\n",
            "0  /content/DynamicBind/input/Conformer3D_COMPOUN...   \n",
            "\n",
            "                             protein_path  \n",
            "0  /content/DynamicBind/input/unnamed.pdb  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "\n",
        "# Create input CSV\n",
        "pdb = os.path.abspath('input/unnamed.pdb') if os.path.exists('input/unnamed.pdb') else None\n",
        "sdf = os.path.abspath('input/Conformer3D_COMPOUND_CID_977.sdf') if os.path.exists('input/Conformer3D_COMPOUND_CID_977.sdf') else None\n",
        "\n",
        "# Auto-detect uploaded files\n",
        "for f in os.listdir('input'):\n",
        "    if f.endswith('.pdb'):\n",
        "        pdb = os.path.abspath(f'input/{f}')\n",
        "    elif f.endswith('.sdf'):\n",
        "        sdf = os.path.abspath(f'input/{f}')\n",
        "\n",
        "if pdb and sdf:\n",
        "    df = pd.DataFrame({'ligand': [sdf], 'protein_path': [pdb]})\n",
        "    df.to_csv('data/input_compounds.csv', index=False)\n",
        "    print(f\"✓ Input CSV created\")\n",
        "    print(df)\n",
        "else:\n",
        "    print(f\"ERROR: Missing files. PDB={pdb}, SDF={sdf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd0d5c54",
      "metadata": {
        "id": "bd0d5c54"
      },
      "source": [
        "## Step 7: Run DynamicBind Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio torch-geometric \\\n",
        "  torch-cluster torch-scatter torch-sparse torch-spline-conv"
      ],
      "metadata": {
        "id": "TiX7Gu6ngRUv"
      },
      "id": "TiX7Gu6ngRUv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch==2.2.0 torchvision torchaudio \\\n",
        "  --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "Iru5tAUlgT2n"
      },
      "id": "Iru5tAUlgT2n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbJebYfMhVE9",
        "outputId": "4e0ac561-4617-4dff-cb20-055e18ec874c"
      },
      "id": "DbJebYfMhVE9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.0+cu118\n",
            "11.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-cluster torch-spline-conv \\\n",
        "  -f https://data.pyg.org/whl/torch-2.2.0+cu118.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gcinUkwhb-0",
        "outputId": "1f468053-d782-480f-cd83-6eeab91107fd"
      },
      "id": "9gcinUkwhb-0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt22cu118)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt22cu118)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt22cu118)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt22cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-geometric"
      ],
      "metadata": {
        "id": "XX8SzDR6jKOY"
      },
      "id": "XX8SzDR6jKOY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<div style=\"font-family: 'Courier New'; font-size:40px; color:#1f77b4;\">\n",
        "런타임 재시작 필요\n",
        "</div>\n",
        "\"\"\"))"
      ],
      "metadata": {
        "id": "Jza8AyTasVWj",
        "outputId": "a4ecc4d4-576a-471f-9250-265812670eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"font-family: 'Courier New'; font-size:40px; color:#1f77b4;\">\n",
              "런타임 재시작 필요\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "Jza8AyTasVWj"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install -q \"numpy<2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FyGzLDUiwpk",
        "outputId": "19cc8952-e2f6-4f3c-e431-832741ae4650"
      },
      "id": "9FyGzLDUiwpk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<div style=\"font-family: 'Courier New'; font-size:40px; color:#1f77b4;\">\n",
        "런타임 재시작 필요\n",
        "</div>\n",
        "\"\"\"))"
      ],
      "metadata": {
        "outputId": "a4ecc4d4-576a-471f-9250-265812670eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "YYsXzntqs0dV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"font-family: 'Courier New'; font-size:40px; color:#1f77b4;\">\n",
              "런타임 재시작 필요\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "YYsXzntqs0dV"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnrdKOEbi1kT",
        "outputId": "2527d2d6-2a7b-445b-dbe2-1f9cf066b6cb"
      },
      "id": "MnrdKOEbi1kT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch_cluster\n",
        "import torch_geometric\n",
        "\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"All OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeBzh355jOVG",
        "outputId": "452778c5-6f53-4bde-9c0f-acaad55e1899"
      },
      "id": "QeBzh355jOVG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "Torch: 2.2.0+cu118\n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0dc52db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0dc52db",
        "outputId": "f7ab6774-ff14-4d28-e43a-1782bad4df8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running DynamicBind inference...\n",
            "\n",
            "(Running in Colab kernel environment)\n",
            "\n",
            "INFO:root:run_single_protein_inference.py data/input_compounds.csv data/input_compounds.csv --protein_path_in_ligandFile --no_clean --ligand_is_sdf --no_relax --samples_per_complex 10 --savings_per_complex 10 --inference_steps 20 --header colab_run --python /usr/bin/python3 --relax_python /usr/bin/python3 --device 0\n",
            "2025_12_24_08_53\n",
            "--------------------------------\n",
            "\n",
            "/content/DynamicBind/run_single_protein_inference.py /content/DynamicBind\n",
            "100% 1/1 [00:00<00:00, 76.55it/s]\n",
            "hub dir /content/DynamicBind/esm_models\n",
            "Transferred model to GPU\n",
            "Read data/prepared_for_esm_colab_run.fasta with 1 sequences\n",
            "Processing 1 of 1 batches (1 sequences)\n",
            "100% 201/201 [01:06<00:00,  3.04it/s]\n",
            "100% 201/201 [01:29<00:00,  2.24it/s]\n",
            "Reading molecules and generating local structures with RDKit\n",
            "1it [00:00, 11.72it/s]\n",
            "Reading language model embeddings.\n",
            "Generating graphs for ligands and proteins\n",
            "loading complexes: 100% 1/1 [00:00<00:00,  5.55it/s]\n",
            "loading data from memory:  data/cache_torsion/limit0_INDEX_maxLigSizeNone_H0_recRad15.0_recMax24_esmEmbeddings4041735646/heterographs.pkl\n",
            "Number of complexes:  1\n",
            "radius protein: mean 22.362150192260742, std 0.0, max 22.362150192260742\n",
            "radius molecule: mean 0.5704739689826965, std 0.0, max 0.5704739689826965\n",
            "distance protein-mol: mean 0.0, std 0.0, max 0.0\n",
            "rmsd matching: mean 0.0, std 0.0, max 0\n",
            "common t schedule [1.   0.95 0.9  0.85 0.8  0.75 0.7  0.65 0.6  0.55 0.5  0.45 0.4  0.35\n",
            " 0.3  0.25 0.2  0.15 0.1  0.05]\n",
            "Size of test dataset:  1\n",
            "1it [00:29, 29.18s/it]\n",
            "Failed for 0 complexes\n",
            "Skipped 0 complexes\n",
            "Results are in results/colab_run\n",
            "inference complete.\n",
            "\n",
            "✓ Inference step complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Detect if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "\n",
        "print(\"Running DynamicBind inference...\\n\")\n",
        "\n",
        "if in_colab:\n",
        "    # Colab: run directly in notebook kernel (all packages installed via pip in Step 2)\n",
        "    print(\"(Running in Colab kernel environment)\\n\")\n",
        "    !python run_single_protein_inference.py \\\n",
        "      data/input_compounds.csv data/input_compounds.csv \\\n",
        "      --protein_path_in_ligandFile \\\n",
        "      --no_clean \\\n",
        "      --ligand_is_sdf \\\n",
        "      --no_relax \\\n",
        "      --samples_per_complex 10 \\\n",
        "      --savings_per_complex 10 \\\n",
        "      --inference_steps 20 \\\n",
        "      --header colab_run \\\n",
        "      --python /usr/bin/python3 \\\n",
        "      --relax_python /usr/bin/python3 \\\n",
        "      --device 0\n",
        "else:\n",
        "    # Local machine: use conda environment for isolation\n",
        "    print(\"(Running with Conda environment 'dynamicbind-minimal')\\n\")\n",
        "    !conda run -n dynamicbind-minimal python run_single_protein_inference.py \\\n",
        "      data/input_compounds.csv data/input_compounds.csv \\\n",
        "      --protein_path_in_ligandFile \\\n",
        "      --no_clean \\\n",
        "      --ligand_is_sdf \\\n",
        "      --no_relax \\\n",
        "      --samples_per_complex 10 \\\n",
        "      --savings_per_complex 10 \\\n",
        "      --inference_steps 20 \\\n",
        "      --header colab_run \\\n",
        "      --python /usr/bin/python3 \\\n",
        "      --relax_python /usr/bin/python3 \\\n",
        "      --device 0\n",
        "\n",
        "print(\"\\n✓ Inference step complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6edd2089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6edd2089",
        "outputId": "fe447bfe-53e1-4617-d8c6-117407d7e149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Diagnostic Check ===\n",
            "\n",
            "1. Checking Conda environment...\n",
            "✓ Running in Colab - conda not available (expected)\n",
            "\n",
            "2. Checking input directory...\n",
            "Files in input/: ['Conformer3D_COMPOUND_CID_977.sdf', 'unnamed.pdb']\n",
            "\n",
            "3. Checking data/input_compounds.csv...\n",
            "✓ CSV file exists\n",
            "ligand,protein_path\n",
            "/content/DynamicBind/input/Conformer3D_COMPOUND_CID_977.sdf,/content/DynamicBind/input/unnamed.pdb\n",
            "\n",
            "\n",
            "4. Checking workdir (model checkpoints)...\n",
            "✓ Model checkpoint found\n",
            "\n",
            "5. Current directory structure:\n",
            "total 448088\n",
            "drwxr-xr-x 13 root root      4096 Dec 24 09:03 .\n",
            "drwxr-xr-x  1 root root      4096 Dec 24 07:36 ..\n",
            "-rw-r--r--  1 root root     24164 Dec 24 07:36 analysis.py\n",
            "-rw-r--r--  1 root root      5662 Dec 24 07:36 check_structure_violations.py\n",
            "-rw-r--r--  1 root root      5066 Dec 24 07:36 clean_pdb.py\n",
            "-rw-r--r--  1 root root     11564 Dec 24 07:36 compute_lddt.py\n",
            "drwxr-xr-x  2 root root      4096 Dec 24 07:36 confidence\n",
            "drwxr-xr-x  4 root root      4096 Dec 24 09:03 data\n",
            "drwxr-xr-x  3 root root      4096 Dec 24 07:46 datasets\n",
            "-rw-r--r--  1 root root  13334630 Dec 24 07:36 dynbind.gif\n",
            "-rw-r--r--  1 root root  11397883 Dec 24 07:36 dynbind.mpg\n",
            "-rw-r--r--  1 root root       778 Dec 24 07:36 environment-minimal.yml\n",
            "-rw-r--r--  1 root root      6230 Dec 24 07:36 environment.yml\n",
            "drwxr-xr-x  6 root root      4096 Dec 24 07:36 esm\n",
            "drwxr-xr-x  3 root root      4096 Dec 24 07:45 esm_models\n",
            "drwxr-xr-x  8 root root      4096 Dec 24 07:36 .git\n",
            "-rw-r--r--  1 root root       277 Dec 24 07:36 .gitignore\n",
            "-rwxr-xr-x  1 root root     56348 Dec 24 07:36 helper_functions.py\n",
            "-rw-r--r--  1 root root     18669 Dec 24 07:36 inference.py\n",
            "drwxr-xr-x  2 root root      4096 Dec 24 08:53 input\n",
            "-rw-r--r--  1 root root      1076 Dec 24 07:36 LICENSE\n",
            "-rw-r--r--  1 root root       915 Dec 24 07:36 merge_screening_results.py\n",
            "drwxr-xr-x  3 root root      4096 Dec 24 08:51 models\n",
            "-rw-r--r--  1 root root      2228 Dec 24 07:36 movie_generation.py\n",
            "-rw-r--r--  1 root root   1558803 Dec 24 07:36 movie_reduced_fuzzed_v2.gif\n",
            "-rw-r--r--  1 root root       106 Dec 24 07:36 oryx-build-commands.txt\n",
            "-rw-r--r--  1 root root 200080136 Dec 24 09:02 .p.npy\n",
            "-rw-r--r--  1 root root      4840 Dec 24 07:36 README.md\n",
            "-rw-r--r--  1 root root     24035 Dec 24 07:36 relax_final.py\n",
            "-rw-r--r--  1 root root      9454 Dec 24 07:36 relax_vis.py\n",
            "-rw-r--r--  1 root root      3527 Dec 24 07:36 remove_gap.py\n",
            "drwxr-xr-x  3 root root      4096 Dec 24 09:03 results\n",
            "-rw-r--r--  1 root root      2818 Dec 24 08:53 run.log\n",
            "-rwxr-xr-x  1 root root      9371 Dec 24 07:36 run_single_protein_inference.py\n",
            "-rw-r--r--  1 root root      2944 Dec 24 07:36 save_reverseprocess.py\n",
            "-rw-r--r--  1 root root 200080136 Dec 24 09:03 .score.npy\n",
            "-rw-r--r--  1 root root     14251 Dec 24 07:36 scoring.py\n",
            "-rw-r--r--  1 root root     14145 Dec 24 07:36 screening.py\n",
            "-rw-r--r--  1 root root      4283 Dec 24 07:36 SETUP_MINIMAL.md\n",
            "-rw-r--r--  1 root root  16000128 Dec 24 09:01 .so3_cdf_vals2.npy\n",
            "-rw-r--r--  1 root root      8128 Dec 24 09:01 .so3_exp_score_norms2.npy\n",
            "-rw-r--r--  1 root root     16128 Dec 24 09:01 .so3_omegas_array2.npy\n",
            "-rw-r--r--  1 root root  16000128 Dec 24 09:01 .so3_score_norms2.npy\n",
            "-rw-r--r--  1 root root     14416 Dec 24 07:36 train.py\n",
            "drwxr-xr-x  3 root root      4096 Dec 24 08:51 utils\n",
            "drwxr-xr-x  4 root root      4096 Dec 24 07:45 workdir\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "\n",
        "print(\"=== Diagnostic Check ===\\n\")\n",
        "\n",
        "print(\"1. Checking Conda environment...\")\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    print(\"✓ Running in Colab - conda not available (expected)\")\n",
        "except ImportError:\n",
        "    result = subprocess.run(['conda', 'env', 'list'], capture_output=True, text=True)\n",
        "    if 'dynamicbind-minimal' in result.stdout:\n",
        "        print(\"✓ dynamicbind-minimal environment found\")\n",
        "    else:\n",
        "        print(\"✗ dynamicbind-minimal environment NOT found\")\n",
        "\n",
        "# Check input directory\n",
        "print(\"\\n2. Checking input directory...\")\n",
        "if os.path.exists('input'):\n",
        "    files = os.listdir('input')\n",
        "    print(f\"Files in input/: {files}\")\n",
        "else:\n",
        "    print(\"✗ input/ directory not found\")\n",
        "\n",
        "# Check CSV file\n",
        "print(\"\\n3. Checking data/input_compounds.csv...\")\n",
        "if os.path.exists('data/input_compounds.csv'):\n",
        "    print(\"✓ CSV file exists\")\n",
        "    with open('data/input_compounds.csv', 'r') as f:\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(\"✗ CSV file not found\")\n",
        "\n",
        "# Check workdir\n",
        "print(\"\\n4. Checking workdir (model checkpoints)...\")\n",
        "if os.path.exists('workdir/big_score_model_sanyueqi_with_time'):\n",
        "    print(\"✓ Model checkpoint found\")\n",
        "else:\n",
        "    print(\"✗ Model checkpoint not found\")\n",
        "    if os.path.exists('workdir'):\n",
        "        print(f\"Contents of workdir/: {os.listdir('workdir')}\")\n",
        "\n",
        "# List all directories\n",
        "print(\"\\n5. Current directory structure:\")\n",
        "result = subprocess.run(['ls', '-la', '/content/DynamicBind'], capture_output=True, text=True)\n",
        "print(result.stdout)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4616a5ed",
      "metadata": {
        "id": "4616a5ed"
      },
      "source": [
        "## Step 8: Check Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f784f29a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f784f29a",
        "outputId": "ea9ae1ab-cf0a-4f8c-c98a-35ba0d49182d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Results directory found: results/colab_run\n",
            "\n",
            "Files in results directory:\n",
            "results/colab_run/complete_affinity_prediction.csv\n",
            "results/colab_run/index0_idx_0/rank8_receptor_lddt0.54_affinity3.25.pdb\n",
            "results/colab_run/index0_idx_0/rank5_receptor_lddt0.65_affinity3.00.pdb\n",
            "results/colab_run/index0_idx_0/rank2_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank4_receptor_lddt0.64_affinity3.44.pdb\n",
            "results/colab_run/index0_idx_0/rank9_receptor_lddt0.50_affinity3.54.pdb\n",
            "results/colab_run/index0_idx_0/rank8_ligand_lddt0.54_affinity3.25.sdf\n",
            "results/colab_run/index0_idx_0/rank9_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank1_ligand_lddt0.70_affinity2.48.sdf\n",
            "results/colab_run/index0_idx_0/rank3_receptor_lddt0.64_affinity2.94.pdb\n",
            "results/colab_run/index0_idx_0/rank10_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank7_receptor_lddt0.56_affinity3.48.pdb\n",
            "results/colab_run/index0_idx_0/Conformer3D_COMPOUND_CID_977.sdf\n",
            "results/colab_run/index0_idx_0/rank2_receptor_lddt0.75_affinity3.22.pdb\n",
            "results/colab_run/index0_idx_0/rank7_ligand_lddt0.56_affinity3.48.sdf\n",
            "results/colab_run/index0_idx_0/rank1_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank5_ligand_lddt0.65_affinity3.00.sdf\n",
            "results/colab_run/index0_idx_0/rank8_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank3_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank2_ligand_lddt0.75_affinity3.22.sdf\n",
            "results/colab_run/index0_idx_0/ref_proteinFile.pdb\n",
            "results/colab_run/index0_idx_0/ref_ligandFile.sdf\n",
            "results/colab_run/index0_idx_0/rank5_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank6_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank6_ligand_lddt0.61_affinity3.55.sdf\n",
            "results/colab_run/index0_idx_0/rank10_receptor_lddt0.51_affinity3.48.pdb\n",
            "results/colab_run/index0_idx_0/rank7_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank9_ligand_lddt0.50_affinity3.54.sdf\n",
            "results/colab_run/index0_idx_0/rank4_reverseprocess_data_list.pkl\n",
            "results/colab_run/index0_idx_0/rank4_ligand_lddt0.64_affinity3.44.sdf\n",
            "results/colab_run/index0_idx_0/rank10_ligand_lddt0.51_affinity3.48.sdf\n",
            "results/colab_run/index0_idx_0/unnamed.pdb\n",
            "results/colab_run/index0_idx_0/rank3_ligand_lddt0.64_affinity2.94.sdf\n",
            "results/colab_run/index0_idx_0/rank6_receptor_lddt0.61_affinity3.55.pdb\n",
            "results/colab_run/index0_idx_0/rank1_receptor_lddt0.70_affinity2.48.pdb\n",
            "results/colab_run/affinity_prediction.csv\n",
            "\n",
            "\n",
            "Generated files summary:\n",
            "4.0K\tresults/colab_run/affinity_prediction.csv\n",
            "4.0K\tresults/colab_run/complete_affinity_prediction.csv\n",
            "21M\tresults/colab_run/index0_idx_0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "\n",
        "# List results\n",
        "results_dir = 'results/colab_run'\n",
        "if os.path.exists(results_dir):\n",
        "    print(f\"✓ Results directory found: {results_dir}\\n\")\n",
        "    result = subprocess.run(['find', results_dir, '-type', 'f'], capture_output=True, text=True)\n",
        "    print(\"Files in results directory:\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Show summary\n",
        "    print(\"\\nGenerated files summary:\")\n",
        "    !du -sh results/colab_run/* 2>/dev/null | head -20\n",
        "else:\n",
        "    print(f\"✗ Results directory not found: {results_dir}\")\n",
        "\n",
        "    # Check for logs\n",
        "    print(\"\\nSearching for log files...\")\n",
        "    log_files = glob.glob('results/**/run.log', recursive=True) + \\\n",
        "                glob.glob('results/**/inference.log', recursive=True) + \\\n",
        "                glob.glob('*.log')\n",
        "\n",
        "    if log_files:\n",
        "        print(f\"Found {len(log_files)} log file(s):\")\n",
        "        for log_file in log_files[:5]:  # Show first 5\n",
        "            print(f\"\\n--- {log_file} ---\")\n",
        "            with open(log_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                print(''.join(lines[-50:]))  # Last 50 lines\n",
        "    else:\n",
        "        print(\"No log files found\")\n",
        "\n",
        "    print(\"\\nAvailable directories:\")\n",
        "    !ls -la results/ 2>/dev/null || echo \"No results directory\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882e373e",
      "metadata": {
        "id": "882e373e"
      },
      "source": [
        "## Step 9: Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06eadbca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "06eadbca",
        "outputId": "7266b88f-1005-4034-fa57-23628f198670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing results for download...\n",
            "Downloading results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4a42de8c-4786-46a2-99ea-bfab7de03330\", \"DynamicBind_results.zip\", 9833793)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Download complete! Check your Downloads folder.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "os.chdir('/content/DynamicBind')\n",
        "\n",
        "results_dir = 'results/colab_run'\n",
        "if os.path.exists(results_dir):\n",
        "    # Create a ZIP of results\n",
        "    print(f\"Preparing results for download...\")\n",
        "    shutil.make_archive('DynamicBind_results', 'zip', results_dir)\n",
        "\n",
        "    # Download\n",
        "    print(f\"Downloading results...\")\n",
        "    files.download('DynamicBind_results.zip')\n",
        "    print(\"\\n✓ Download complete! Check your Downloads folder.\")\n",
        "else:\n",
        "    print(f\"ERROR: Results directory not found. Check inference output above for errors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5b168f5",
      "metadata": {
        "id": "d5b168f5"
      },
      "source": [
        "## Summary\n",
        "\n",
        "You have completed DynamicBind inference on Google Colab!\n",
        "\n",
        "**Output files include:**\n",
        "- Ranked poses (`.sdf` and `.pdb` files) for the ligand-protein complex\n",
        "- Affinity predictions (`.csv`)\n",
        "- Intermediate data for visualization (`.pkl` files)\n",
        "\n",
        "**Next steps:**\n",
        "1. Download the ZIP file with all results\n",
        "2. Extract and analyze the predicted complexes in your preferred molecular viewer (e.g., PyMOL, Chimera)\n",
        "3. Evaluate binding affinities and pose quality\n",
        "\n",
        "For more details, see: [DynamicBind Paper](https://www.nature.com/articles/s41467-024-45461-2)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}