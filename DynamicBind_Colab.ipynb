{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1f93c1",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Go to Runtime > Change runtime type and select GPU.\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/content')\n",
    "\n",
    "# If a non-git `DynamicBind` folder exists, remove it so a fresh clone can proceed\n",
    "if os.path.exists('DynamicBind') and not os.path.exists(os.path.join('DynamicBind', '.git')):\n",
    "    print(\"Removing non-git 'DynamicBind' directory to allow fresh clone...\")\n",
    "    shutil.rmtree('DynamicBind')\n",
    "\n",
    "# Clone from original repo (or you can upload a ZIP)\n",
    "if not os.path.exists('DynamicBind'):\n",
    "    print(\"Cloning DynamicBind repository...\")\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/luwei0917/DynamicBind.git', 'DynamicBind'], check=True)\n",
    "    print(\"✓ Repository cloned\")\n",
    "else:\n",
    "    print(\"✓ Repository already exists (git repo)\")\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b2184",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing PyTorch...\")\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"Installing PyTorch Geometric...\")\n",
    "!pip install -q torch-geometric\n",
    "\n",
    "print(\"Installing RDKit and other dependencies...\")\n",
    "!pip install -q rdkit biopython pandas numpy scipy scikit-learn matplotlib tqdm pyyaml requests\n",
    "\n",
    "print(\"Installing ESM and spyrmsd...\")\n",
    "!pip install -q fair-esm spyrmsd e3nn\n",
    "\n",
    "print(\"\\n✓ All dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5304492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "print(\"Setting up Conda environment for DynamicBind...\")\n",
    "print(\"This step ensures all PyTorch Geometric dependencies are installed.\\n\")\n",
    "\n",
    "# Create conda environment from environment-minimal.yml\n",
    "if not os.path.exists(os.path.expanduser('~/miniconda3/envs/dynamicbind-minimal')):\n",
    "    print(\"Creating dynamicbind-minimal environment...\")\n",
    "    result = subprocess.run(['conda', 'env', 'create', '-f', 'environment-minimal.yml', '-y'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ Environment created successfully\")\n",
    "    else:\n",
    "        print(\"⚠ Environment creation had issues:\")\n",
    "        print(result.stderr[-500:])  # Last 500 chars\n",
    "else:\n",
    "    print(\"✓ Environment already exists\")\n",
    "\n",
    "# Verify torch_cluster is installed\n",
    "print(\"\\nVerifying torch_cluster installation...\")\n",
    "result = subprocess.run(['conda', 'run', '-n', 'dynamicbind-minimal', 'python', '-c', \n",
    "                        'import torch_cluster; print(\"✓ torch_cluster found\")'],\n",
    "                       capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout.strip())\n",
    "else:\n",
    "    print(\"⚠ torch_cluster not found, installing...\")\n",
    "    subprocess.run(['conda', 'install', '-n', 'dynamicbind-minimal', \n",
    "                   '-c', 'pytorch', 'pytorch-cluster', '-y'],\n",
    "                  capture_output=True)\n",
    "    print(\"✓ torch_cluster installed\")\n",
    "\n",
    "print(\"\\n✓ Conda environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e64225",
   "metadata": {},
   "source": [
    "## Step 3: Clone/Setup DynamicBind Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "os.chdir('/content')\n",
    "\n",
    "# Clone from original repo (or you can upload a ZIP)\n",
    "if not os.path.exists('DynamicBind'):\n",
    "    !git clone https://github.com/luwei0917/DynamicBind.git\n",
    "    print(\"✓ Repository cloned\")\n",
    "else:\n",
    "    print(\"✓ Repository already exists\")\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab327d0",
   "metadata": {},
   "source": [
    "## Step 4: Download Model Checkpoints from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc320d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "os.makedirs('workdir', exist_ok=True)\n",
    "\n",
    "# Download checkpoint from Zenodo (v2)\n",
    "checkpoint_url = 'https://zenodo.org/records/10183369/files/workdir.zip'\n",
    "checkpoint_file = 'workdir.zip'\n",
    "\n",
    "if not os.path.exists(os.path.join('workdir', 'big_score_model_sanyueqi_with_time')):\n",
    "    print(f\"Downloading model checkpoint from Zenodo (may take 5-10 minutes)...\")\n",
    "    !wget -O {checkpoint_file} {checkpoint_url}\n",
    "    print(\"Extracting...\")\n",
    "    !unzip -o {checkpoint_file} -d workdir\n",
    "    # Fix nested directory structure if needed\n",
    "    if os.path.exists('workdir/workdir'):\n",
    "        !mv workdir/workdir/* workdir/\n",
    "        !rmdir workdir/workdir\n",
    "    print(\"✓ Checkpoints ready\")\n",
    "    !rm {checkpoint_file}\n",
    "else:\n",
    "    print(\"✓ Checkpoints already available\")\n",
    "\n",
    "print(f\"Workdir contents: {os.listdir('workdir')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe7cf8",
   "metadata": {},
   "source": [
    "## Step 5: Upload Input Files (PDB & SDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "os.makedirs('/content/DynamicBind/input', exist_ok=True)\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "print(\"Upload your protein PDB file and ligand SDF file.\")\n",
    "print(\"Click 'Choose Files' and select both files.\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "pdb_file = None\n",
    "sdf_file = None\n",
    "\n",
    "for fname in uploaded.keys():\n",
    "    if fname.endswith('.pdb'):\n",
    "        pdb_file = f'input/{fname}'\n",
    "        os.rename(fname, pdb_file)\n",
    "    elif fname.endswith('.sdf'):\n",
    "        sdf_file = f'input/{fname}'\n",
    "        os.rename(fname, sdf_file)\n",
    "\n",
    "if pdb_file and sdf_file:\n",
    "    print(f\"✓ PDB: {pdb_file}\")\n",
    "    print(f\"✓ SDF: {sdf_file}\")\n",
    "else:\n",
    "    print(\"ERROR: Please upload both PDB and SDF files.\")\n",
    "    if pdb_file:\n",
    "        print(f\"  PDB found: {pdb_file}\")\n",
    "    if sdf_file:\n",
    "        print(f\"  SDF found: {sdf_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70b64b",
   "metadata": {},
   "source": [
    "## Step 6: Prepare Input CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "# Create input CSV\n",
    "pdb = os.path.abspath('input/unnamed.pdb') if os.path.exists('input/unnamed.pdb') else None\n",
    "sdf = os.path.abspath('input/Conformer3D_COMPOUND_CID_977.sdf') if os.path.exists('input/Conformer3D_COMPOUND_CID_977.sdf') else None\n",
    "\n",
    "# Auto-detect uploaded files\n",
    "for f in os.listdir('input'):\n",
    "    if f.endswith('.pdb'):\n",
    "        pdb = os.path.abspath(f'input/{f}')\n",
    "    elif f.endswith('.sdf'):\n",
    "        sdf = os.path.abspath(f'input/{f}')\n",
    "\n",
    "if pdb and sdf:\n",
    "    df = pd.DataFrame({'ligand': [sdf], 'protein_path': [pdb]})\n",
    "    df.to_csv('data/input_compounds.csv', index=False)\n",
    "    print(f\"✓ Input CSV created\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"ERROR: Missing files. PDB={pdb}, SDF={sdf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d5c54",
   "metadata": {},
   "source": [
    "## Step 7: Run DynamicBind Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "print(\"Running DynamicBind inference with Conda environment...\\n\")\n",
    "\n",
    "# Run inference using conda environment via shell command\n",
    "# This ensures torch_cluster and other PyG dependencies are available\n",
    "!conda run -n dynamicbind-minimal python run_single_protein_inference.py \\\n",
    "  data/input_compounds.csv data/input_compounds.csv \\\n",
    "  --protein_path_in_ligandFile \\\n",
    "  --no_clean \\\n",
    "  --ligand_is_sdf \\\n",
    "  --no_relax \\\n",
    "  --samples_per_complex 10 \\\n",
    "  --savings_per_complex 10 \\\n",
    "  --inference_steps 20 \\\n",
    "  --header colab_run \\\n",
    "  --python /usr/bin/python3 \\\n",
    "  --relax_python /usr/bin/python3 \\\n",
    "  --device 0\n",
    "\n",
    "print(\"\\n✓ Inference step complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "print(\"=== Diagnostic Check ===\\n\")\n",
    "\n",
    "# Check conda environment\n",
    "print(\"1. Checking Conda environment...\")\n",
    "result = subprocess.run(['conda', 'env', 'list'], capture_output=True, text=True)\n",
    "if 'dynamicbind-minimal' in result.stdout:\n",
    "    print(\"✓ dynamicbind-minimal environment found\")\n",
    "else:\n",
    "    print(\"✗ dynamicbind-minimal environment NOT found\")\n",
    "    print(\"Available environments:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "# Check input directory\n",
    "print(\"\\n2. Checking input directory...\")\n",
    "if os.path.exists('input'):\n",
    "    files = os.listdir('input')\n",
    "    print(f\"Files in input/: {files}\")\n",
    "else:\n",
    "    print(\"✗ input/ directory not found\")\n",
    "\n",
    "# Check CSV file\n",
    "print(\"\\n3. Checking data/input_compounds.csv...\")\n",
    "if os.path.exists('data/input_compounds.csv'):\n",
    "    print(\"✓ CSV file exists\")\n",
    "    with open('data/input_compounds.csv', 'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"✗ CSV file not found\")\n",
    "\n",
    "# Check workdir\n",
    "print(\"\\n4. Checking workdir (model checkpoints)...\")\n",
    "if os.path.exists('workdir/big_score_model_sanyueqi_with_time'):\n",
    "    print(\"✓ Model checkpoint found\")\n",
    "else:\n",
    "    print(\"✗ Model checkpoint not found\")\n",
    "    if os.path.exists('workdir'):\n",
    "        print(f\"Contents of workdir/: {os.listdir('workdir')}\")\n",
    "\n",
    "# List all directories\n",
    "print(\"\\n5. Current directory structure:\")\n",
    "result = subprocess.run(['ls', '-la', '/content/DynamicBind'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616a5ed",
   "metadata": {},
   "source": [
    "## Step 8: Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "# List results\n",
    "results_dir = 'results/colab_run'\n",
    "if os.path.exists(results_dir):\n",
    "    print(f\"✓ Results directory found: {results_dir}\\n\")\n",
    "    result = subprocess.run(['find', results_dir, '-type', 'f'], capture_output=True, text=True)\n",
    "    print(\"Files in results directory:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    # Show summary\n",
    "    print(\"\\nGenerated files summary:\")\n",
    "    !du -sh results/colab_run/* 2>/dev/null | head -20\n",
    "else:\n",
    "    print(f\"✗ Results directory not found: {results_dir}\")\n",
    "    \n",
    "    # Check for logs\n",
    "    print(\"\\nSearching for log files...\")\n",
    "    log_files = glob.glob('results/**/run.log', recursive=True) + \\\n",
    "                glob.glob('results/**/inference.log', recursive=True) + \\\n",
    "                glob.glob('*.log')\n",
    "    \n",
    "    if log_files:\n",
    "        print(f\"Found {len(log_files)} log file(s):\")\n",
    "        for log_file in log_files[:5]:  # Show first 5\n",
    "            print(f\"\\n--- {log_file} ---\")\n",
    "            with open(log_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                print(''.join(lines[-50:]))  # Last 50 lines\n",
    "    else:\n",
    "        print(\"No log files found\")\n",
    "    \n",
    "    print(\"\\nAvailable directories:\")\n",
    "    !ls -la results/ 2>/dev/null || echo \"No results directory\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e373e",
   "metadata": {},
   "source": [
    "## Step 9: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eadbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "os.chdir('/content/DynamicBind')\n",
    "\n",
    "results_dir = 'results/colab_run'\n",
    "if os.path.exists(results_dir):\n",
    "    # Create a ZIP of results\n",
    "    print(f\"Preparing results for download...\")\n",
    "    shutil.make_archive('DynamicBind_results', 'zip', results_dir)\n",
    "    \n",
    "    # Download\n",
    "    print(f\"Downloading results...\")\n",
    "    files.download('DynamicBind_results.zip')\n",
    "    print(\"\\n✓ Download complete! Check your Downloads folder.\")\n",
    "else:\n",
    "    print(f\"ERROR: Results directory not found. Check inference output above for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b168f5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You have completed DynamicBind inference on Google Colab!\n",
    "\n",
    "**Output files include:**\n",
    "- Ranked poses (`.sdf` and `.pdb` files) for the ligand-protein complex\n",
    "- Affinity predictions (`.csv`)\n",
    "- Intermediate data for visualization (`.pkl` files)\n",
    "\n",
    "**Next steps:**\n",
    "1. Download the ZIP file with all results\n",
    "2. Extract and analyze the predicted complexes in your preferred molecular viewer (e.g., PyMOL, Chimera)\n",
    "3. Evaluate binding affinities and pose quality\n",
    "\n",
    "For more details, see: [DynamicBind Paper](https://www.nature.com/articles/s41467-024-45461-2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
